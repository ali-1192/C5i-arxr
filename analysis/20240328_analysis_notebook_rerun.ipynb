{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02d992aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import google.cloud.aiplatform as aiplatform\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from utils import generate_prompt_categories,obtain_results_gemini_uid_dict,generate_prompt,generate_prompt_batch,run_llm_label_flow,load_in_data,grab_specific_tag_data_breakdown_test_and_train,chunk_dataframe_into_batches,run_llm_label_flow_gemini\n",
    "from constants import query_tags,sentiment_dict\n",
    "from sklearn.metrics import classification_report\n",
    "pd.set_option('max_colwidth', 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a18ac5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To add to utils \n",
    "def combine_results_data(all_data,exclude_ids,results_df):\n",
    "    data_excluded = all_data.loc[all_data['uid'].isin(exclude_ids)].reset_index(drop=True)\n",
    "    text_map = {text:label for text,label in zip(results_df['text'],results_df['llm_label'])}\n",
    "    data_excluded['llm_label'] = data_excluded['text'].apply(lambda x: text_map[x] if x in text_map.keys() else None).reset_index(drop=True)\n",
    "    data_excluded = data_excluded.loc[~data_excluded['llm_label'].isna()].reset_index(drop=True)\n",
    "    all_results = pd.concat([results_df,data_excluded]).reset_index(drop=True)\n",
    "    return all_results\n",
    "\n",
    "\n",
    "def make_preds(query,tag):\n",
    "    # Load in main data\n",
    "    main_query_data = load_in_data(query)\n",
    "    \n",
    "    # Load in sampled data\n",
    "    all_data, unique_text_data, excluded_uid_data, train_data, test_data = grab_specific_tag_data_breakdown_test_and_train(main_query_data,tag)\n",
    "    \n",
    "    # Condition for sample \n",
    "    if len(train_data)>5000:\n",
    "        train_data = train_data.sample(n=5000,random_state=42)\n",
    "        \n",
    "    # Create prompt and make preds\n",
    "    prompt = generate_prompt(query.title(), tag.title())\n",
    "    results = run_llm_label_flow_gemini(sentiment_dict, prompt, list(sentiment_dict.keys()), train_data, label_name='llm_label')\n",
    "    \n",
    "    print(f'The label distribution for {query} {tag} is: \\n with singular results')\n",
    "    print(results['llm_label'].value_counts()/len(results))\n",
    "    \n",
    "    # Combine text to label \n",
    "    all_results = combine_results_data(all_data,excluded_uid_data,results)\n",
    "    \n",
    "    print(f'The label distribution for {query} {tag} is: \\n with all results')\n",
    "    print(all_results['llm_label'].value_counts()/len(all_results))\n",
    "    \n",
    "    # Save data\n",
    "    all_results.to_json(f'../data/predictions/{query}/{tag}.json',orient='records',lines=True)\n",
    "    print('Complete')\n",
    "\n",
    "def make_preds_categories(query,tag):\n",
    "    # Load in main data\n",
    "    main_query_data = load_in_data(query)\n",
    "    \n",
    "    # Load in sampled data\n",
    "    all_data, unique_text_data, excluded_uid_data, train_data, test_data = grab_specific_tag_data_breakdown_test_and_train(main_query_data,tag)\n",
    "    \n",
    "    # Condition for sample \n",
    "    if len(train_data)>5000:\n",
    "        train_data = train_data.sample(n=5000,random_state=42)\n",
    "        \n",
    "    # Create prompt and make preds\n",
    "    prompt = generate_prompt_categories(tag.title())\n",
    "    results = run_llm_label_flow_gemini(sentiment_dict, prompt, list(sentiment_dict.keys()), train_data, label_name='llm_label')\n",
    "    \n",
    "    print(f'The label distribution for {query} {tag} is: \\n with singular results')\n",
    "    print(results['llm_label'].value_counts()/len(results))\n",
    "    \n",
    "    # Combine text to label \n",
    "    all_results = combine_results_data(all_data,excluded_uid_data,results)\n",
    "    \n",
    "    print(f'The label distribution for {query} {tag} is: \\n with all results')\n",
    "    print(all_results['llm_label'].value_counts()/len(all_results))\n",
    "    \n",
    "    # Save data\n",
    "    all_results.to_json(f'../data/predictions/{query}/{tag}.json',orient='records',lines=True)\n",
    "    print('Complete')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21041c13",
   "metadata": {},
   "source": [
    "# Creating pipeline workflow for fast processing \n",
    "\n",
    "\n",
    "args: query,tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dce6df01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename all files \n",
    "# Rename files in directory\n",
    "import logging\n",
    "import glob\n",
    "def rename_files(tag):\n",
    "    file_paths = glob.glob(f\"../data/{tag}/*.csv\")\n",
    "    for file in file_paths:\n",
    "        os.system(f\" mv {file} {file.replace(tag.title()+'_','').lower()}\")\n",
    "        logging.info(f\"Finished processing for {tag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55120a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preds(query,tag):\n",
    "    # Load in main data\n",
    "    rename_files(tag)\n",
    "    main_query_data = load_in_data(query)\n",
    "    \n",
    "    # Load in sampled data\n",
    "    all_data, unique_text_data, excluded_uid_data, train_data, test_data = grab_specific_tag_data_breakdown_test_and_train(main_query_data,tag)\n",
    "    \n",
    "    # Condition for sample \n",
    "    if len(train_data)>5000:\n",
    "        train_data = train_data.sample(n=5000,random_state=42)\n",
    "        \n",
    "    # Create prompt and make preds\n",
    "    prompt = generate_prompt(query.title(), tag.title())\n",
    "    results = run_llm_label_flow_gemini(sentiment_dict, prompt, list(sentiment_dict.keys()), train_data, label_name='llm_label')\n",
    "    \n",
    "    print(f'The label distribution for {query} {tag} is: \\n with singular results')\n",
    "    print(results['llm_label'].value_counts()/len(results))\n",
    "    \n",
    "    # Combine text to label \n",
    "    all_results = combine_results_data(all_data,excluded_uid_data,results)\n",
    "    \n",
    "    print(f'The label distribution for {query} {tag} is: \\n with all results')\n",
    "    print(all_results['llm_label'].value_counts()/len(all_results))\n",
    "    \n",
    "    # Save data\n",
    "    all_results.to_json(f'../data/predictions/{query}/{tag}.json',orient='records',lines=True)\n",
    "    print('Complete')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fe0cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/glasses/apple.csv'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob(f\"../data/glasses/*.csv\")[0].replace(\"Glasses_\",'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a0626b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename all files \n",
    "# Rename files in directory\n",
    "import logging\n",
    "import glob\n",
    "def rename_files(tag):\n",
    "    file_paths = glob.glob(f\"../data/{tag}/*.csv\")\n",
    "    for file in file_paths:\n",
    "        os.system(f\" mv {file} {file.replace(tag.title()+'_','').lower()}\")\n",
    "        logging.info(f\"Finished processing for {tag}\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "47674ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in glob.glob(f\"../data/categories/*.csv\"):\n",
    "    os.system(f\" mv {file} {file.replace('category','categories')} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43efa6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(f\"../data/glasses/apple.csv\",header=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adceb9ed",
   "metadata": {},
   "source": [
    "# Glasses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8bf64854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "glasses meta\n",
      "['/Users/pvacca/git/project-google-arxr-analytics/data/glasses/google.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/lenovo.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/snap.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/apple.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/vuzix.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/rokid.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/meta.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,52,54,56,59,61,62,72,96,100,108,111) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path,header=10)\n",
      "100%|██████████| 5000/5000 [08:55<00:00,  9.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label distribution for glasses meta is: \n",
      " with singular results\n",
      "llm_label\n",
      "0    0.755779\n",
      "1    0.162814\n",
      "2    0.081407\n",
      "Name: count, dtype: float64\n",
      "The label distribution for glasses meta is: \n",
      " with all results\n",
      "llm_label\n",
      "0.0    0.758194\n",
      "1.0    0.161138\n",
      "2.0    0.080667\n",
      "Name: count, dtype: float64\n",
      "Complete\n",
      "glasses rokid\n",
      "['/Users/pvacca/git/project-google-arxr-analytics/data/glasses/google.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/lenovo.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/snap.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/apple.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/vuzix.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/rokid.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/meta.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,52,54,56,59,61,62,72,96,100,108,111) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path,header=10)\n",
      "100%|██████████| 1279/1279 [02:16<00:00,  9.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label distribution for glasses rokid is: \n",
      " with singular results\n",
      "llm_label\n",
      "0    0.752941\n",
      "2    0.123922\n",
      "1    0.123137\n",
      "Name: count, dtype: float64\n",
      "The label distribution for glasses rokid is: \n",
      " with all results\n",
      "llm_label\n",
      "0.0    0.756744\n",
      "2.0    0.165277\n",
      "1.0    0.077979\n",
      "Name: count, dtype: float64\n",
      "Complete\n",
      "glasses snap\n",
      "['/Users/pvacca/git/project-google-arxr-analytics/data/glasses/google.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/lenovo.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/snap.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/apple.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/vuzix.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/rokid.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/meta.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,52,54,56,59,61,62,72,96,100,108,111) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path,header=10)\n",
      "100%|██████████| 440/440 [00:47<00:00,  9.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label distribution for glasses snap is: \n",
      " with singular results\n",
      "llm_label\n",
      "0    0.779343\n",
      "2    0.112676\n",
      "1    0.107981\n",
      "Name: count, dtype: float64\n",
      "The label distribution for glasses snap is: \n",
      " with all results\n",
      "llm_label\n",
      "0.0    0.785877\n",
      "2.0    0.109339\n",
      "1.0    0.104784\n",
      "Name: count, dtype: float64\n",
      "Complete\n",
      "glasses vuzix\n",
      "['/Users/pvacca/git/project-google-arxr-analytics/data/glasses/google.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/lenovo.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/snap.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/apple.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/vuzix.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/rokid.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/meta.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,52,54,56,59,61,62,72,96,100,108,111) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path,header=10)\n",
      "100%|██████████| 168/168 [00:17<00:00,  9.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label distribution for glasses vuzix is: \n",
      " with singular results\n",
      "llm_label\n",
      "0    0.648810\n",
      "2    0.244048\n",
      "1    0.107143\n",
      "Name: count, dtype: float64\n",
      "The label distribution for glasses vuzix is: \n",
      " with all results\n",
      "llm_label\n",
      "0.0    0.613260\n",
      "2.0    0.226519\n",
      "1.0    0.160221\n",
      "Name: count, dtype: float64\n",
      "Complete\n",
      "glasses xreal\n",
      "['/Users/pvacca/git/project-google-arxr-analytics/data/glasses/google.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/lenovo.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/snap.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/apple.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/vuzix.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/rokid.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/glasses/meta.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,52,54,56,59,61,62,72,96,100,108,111) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path,header=10)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0 unless no samples are taken",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query,tag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(querys,tags):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(query,tag)\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mmake_preds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[31], line 7\u001b[0m, in \u001b[0;36mmake_preds\u001b[0;34m(query, tag)\u001b[0m\n\u001b[1;32m      4\u001b[0m main_query_data \u001b[38;5;241m=\u001b[39m load_in_data(query)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load in sampled data\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m all_data, unique_text_data, excluded_uid_data, train_data, test_data \u001b[38;5;241m=\u001b[39m \u001b[43mgrab_specific_tag_data_breakdown_test_and_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain_query_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Condition for sample \u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(train_data)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m5000\u001b[39m:\n",
      "File \u001b[0;32m~/git/project-google-arxr-analytics/analysis/utils.py:361\u001b[0m, in \u001b[0;36mgrab_specific_tag_data_breakdown_test_and_train\u001b[0;34m(df, tag)\u001b[0m\n\u001b[1;32m    359\u001b[0m df_unique_snippets \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mdrop_duplicates(subset\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    360\u001b[0m excluded_uid_from_unique \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muid\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mset\u001b[39m(df_unique_snippets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muid\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 361\u001b[0m df_test \u001b[38;5;241m=\u001b[39m  \u001b[43mdf_unique_snippets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    362\u001b[0m df_test_uids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muid\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    363\u001b[0m df_train \u001b[38;5;241m=\u001b[39m  df_unique_snippets\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39mdf_unique_snippets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muid\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(df_test_uids)]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/git/project-google-arxr-analytics/.venv/lib/python3.9/site-packages/pandas/core/generic.py:6118\u001b[0m, in \u001b[0;36mNDFrame.sample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis, ignore_index)\u001b[0m\n\u001b[1;32m   6115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   6116\u001b[0m     weights \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mpreprocess_weights(\u001b[38;5;28mself\u001b[39m, weights, axis)\n\u001b[0;32m-> 6118\u001b[0m sampled_indices \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6119\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(sampled_indices, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_index:\n",
      "File \u001b[0;32m~/git/project-google-arxr-analytics/.venv/lib/python3.9/site-packages/pandas/core/sample.py:152\u001b[0m, in \u001b[0;36msample\u001b[0;34m(obj_len, size, replace, weights, random_state)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid weights: weights sum to zero\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mastype(\n\u001b[1;32m    153\u001b[0m     np\u001b[38;5;241m.\u001b[39mintp, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    154\u001b[0m )\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:945\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be greater than 0 unless no samples are taken"
     ]
    }
   ],
   "source": [
    "# Glasses \n",
    "# Go do and make preds for all\n",
    "\n",
    "#tags = ['meta','rokid','snap','vuzix','xreal','google','apple','lenovo']\n",
    "tags = ['xreal','google','apple','lenovo']\n",
    "querys = ['glasses' for i in range(len(tags))]\n",
    "\n",
    "for query,tag in zip(querys,tags):\n",
    "    print(query,tag)\n",
    "    make_preds(query,tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0637b91b",
   "metadata": {},
   "source": [
    "# Load in all glasses data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e026212a",
   "metadata": {},
   "outputs": [],
   "source": [
    "glasses_predictions = glob.glob('../data/predictions/glasses/*')\n",
    "data = []\n",
    "for path in glasses_predictions:\n",
    "    df = pd.read_json(path,orient='records',lines=True)\n",
    "    data.append(df)\n",
    "all_glasses_preds = pd.concat(data).reset_index(drop=True)\n",
    "all_glasses_preds['query'] = 'glasses'\n",
    "all_glasses_preds.to_json('../data/predictions/final_preds/glasses.json',orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d30dc8",
   "metadata": {},
   "source": [
    "# Data Quality Check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "b439f9c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22669</th>\n",
       "      <td>RT @steepler @bexhillmuseum @WollastonMuseum I did a Google glass search on it and that’s the most likely thing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22673</th>\n",
       "      <td>@GoogleARVR @peregrau1969 @unity Google augmented reality glasses project: These are four links about mixed reality technologies. Therefore, we ask engineers and workers to conduct research in order to take advantage of all technologies and innovations and create hologram projects &amp;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22674</th>\n",
       "      <td>RT @verge Google Glass Enterprise Edition is no more https://t.co/EiKr87RM72 https://t.co/zO3dkonuT9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22677</th>\n",
       "      <td>@MKBHD The same basic idea of google glass, but covering the whole face...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22679</th>\n",
       "      <td>@tnatw Use of chat with Google glasses, for jury selection to read micro expressions. Then constantly redirecting chat throughout the trial, to cater questioning and objections to the flow of information. Smarter lawyers will be a must, parameters will change for every trial.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29915</th>\n",
       "      <td>Google Glass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29916</th>\n",
       "      <td>Google Glass.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29917</th>\n",
       "      <td>Google Glass.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29918</th>\n",
       "      <td>Google Glass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29919</th>\n",
       "      <td>Google glasses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2982 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                              text\n",
       "22669                                                                                                                                                                             RT @steepler @bexhillmuseum @WollastonMuseum I did a Google glass search on it and that’s the most likely thing.\n",
       "22673  @GoogleARVR @peregrau1969 @unity Google augmented reality glasses project: These are four links about mixed reality technologies. Therefore, we ask engineers and workers to conduct research in order to take advantage of all technologies and innovations and create hologram projects &\n",
       "22674                                                                                                                                                                                         RT @verge Google Glass Enterprise Edition is no more https://t.co/EiKr87RM72 https://t.co/zO3dkonuT9\n",
       "22677                                                                                                                                                                                                                   @MKBHD The same basic idea of google glass, but covering the whole face...\n",
       "22679         @tnatw Use of chat with Google glasses, for jury selection to read micro expressions. Then constantly redirecting chat throughout the trial, to cater questioning and objections to the flow of information. Smarter lawyers will be a must, parameters will change for every trial.\n",
       "...                                                                                                                                                                                                                                                                                            ...\n",
       "29915                                                                                                                                                                                                                                                                                 Google Glass\n",
       "29916                                                                                                                                                                                                                                                                                Google Glass.\n",
       "29917                                                                                                                                                                                                                                                                                Google Glass.\n",
       "29918                                                                                                                                                                                                                                                                                 Google Glass\n",
       "29919                                                                                                                                                                                                                                                                               Google glasses\n",
       "\n",
       "[2982 rows x 1 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_glasses_preds.loc[(all_glasses_preds['tag']=='google') & (all_glasses_preds['llm_label']==1) ][['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa29c42",
   "metadata": {},
   "source": [
    "# Headsets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "471a9c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/pvacca/git/project-google-arxr-analytics/data/headsets/magic_leap.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/headsets/google.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/headsets/oppo.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/headsets/sony.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/headsets/apple.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/headsets/dpvr.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/headsets/hp.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/headsets/pico.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/headsets/meta.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/headsets/microsoft.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/headsets/samsung.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/headsets/htc.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,52,54,56,61,62,72,105,107,108,109,110,111) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path,header=10)\n",
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,52,54,56,59,61,62,72,111) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path,header=10)\n",
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,52,54,56,61,62,72,110,112) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path,header=10)\n",
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,51,52,54,56,59,61,62,72,94,96,100,101,105,106,109,110,111) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path,header=10)\n",
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,51,52,54,56,59,61,62,72,94,101,106,110) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path,header=10)\n",
      "100%|██████████| 5000/5000 [09:01<00:00,  9.23it/s]\n"
     ]
    }
   ],
   "source": [
    "tags = ['apple',\n",
    " 'dpvr',\n",
    " 'google',\n",
    " 'hp',\n",
    " 'htc',\n",
    " 'magic_leap',\n",
    " 'meta',\n",
    " 'microsoft',\n",
    " 'oppo',\n",
    " 'pico',\n",
    " 'samsung',\n",
    " 'sony',\n",
    " 'valve']\n",
    "querys = ['headsets' for i in range(len(tags))]\n",
    "\n",
    "for query,tag in zip(querys,tags):\n",
    "    make_preds(query,tag)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db2ced1",
   "metadata": {},
   "source": [
    "# Categories "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd29d71",
   "metadata": {},
   "source": [
    "### Unlike the other queries we need to adjust the prompt---using Gemini we'll optimize the prompt for best results based on true labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6380e1de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/pvacca/git/project-google-arxr-analytics/data/categories/google.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/categories/amazon.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/categories/apple.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/categories/meta.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/categories/microsoft.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,52,54,56,59,61,62,72) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df['tag'] = path.split('/')[-1].split('.')[0].replace(f'{query}_','')\n",
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,52,54,56,59,61,62,72,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df['tag'] = path.split('/')[-1].split('.')[0].replace(f'{query}_','')\n",
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,52,54,56,61,62,72,100,112) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df['tag'] = path.split('/')[-1].split('.')[0].replace(f'{query}_','')\n",
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,51,52,54,56,59,61,62,72,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df['tag'] = path.split('/')[-1].split('.')[0].replace(f'{query}_','')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/pvacca/git/project-google-arxr-analytics/data/categories/google.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/categories/amazon.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/categories/apple.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/categories/meta.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/categories/microsoft.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,52,54,56,59,61,62,72) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df['tag'] = path.split('/')[-1].split('.')[0].replace(f'{query}_','')\n",
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,52,54,56,59,61,62,72,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df['tag'] = path.split('/')[-1].split('.')[0].replace(f'{query}_','')\n",
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,52,54,56,61,62,72,100,112) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df['tag'] = path.split('/')[-1].split('.')[0].replace(f'{query}_','')\n",
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,51,52,54,56,59,61,62,72,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df['tag'] = path.split('/')[-1].split('.')[0].replace(f'{query}_','')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/pvacca/git/project-google-arxr-analytics/data/categories/google.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/categories/amazon.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/categories/apple.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/categories/meta.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/categories/microsoft.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,52,54,56,59,61,62,72) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df['tag'] = path.split('/')[-1].split('.')[0].replace(f'{query}_','')\n",
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,52,54,56,59,61,62,72,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df['tag'] = path.split('/')[-1].split('.')[0].replace(f'{query}_','')\n",
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,52,54,56,61,62,72,100,112) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df['tag'] = path.split('/')[-1].split('.')[0].replace(f'{query}_','')\n",
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,51,52,54,56,59,61,62,72,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df['tag'] = path.split('/')[-1].split('.')[0].replace(f'{query}_','')\n"
     ]
    }
   ],
   "source": [
    "#rename_files('categories')\n",
    "cat_data = load_in_data('categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12ae1d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df,df_unique_snippets,excluded_uid_from_unique, df_train, df_test = grab_specific_tag_data_breakdown_test_and_train(cat_data,'apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9bfb017a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['manual_export'], dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd3b481e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('../data/categories_test_data/apple_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34852fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:05<00:00,  9.48it/s]\n"
     ]
    }
   ],
   "source": [
    "# Step 1 run results with gemini \n",
    "prompt = generate_prompt_categories('Apple')\n",
    "results = run_llm_label_flow_gemini(sentiment_dict, prompt, list(sentiment_dict.keys()), df_test, label_name='llm_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f236aa62",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('../data/categories_test_data/apple_test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2b8527e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pageType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/git/project-google-arxr-analytics/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pageType'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[47], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpageType\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39munique()\n",
      "File \u001b[0;32m~/git/project-google-arxr-analytics/.venv/lib/python3.9/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/git/project-google-arxr-analytics/.venv/lib/python3.9/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'pageType'"
     ]
    }
   ],
   "source": [
    "df['pageType'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "44afc355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/pvacca/git/project-google-arxr-analytics/data/categories/google.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/categories/amazon.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/categories/apple.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/categories/meta.csv', '/Users/pvacca/git/project-google-arxr-analytics/data/categories/microsoft.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,52,54,56,59,61,62,72) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path,header=10)\n",
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,52,54,56,59,61,62,72,111,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path,header=10)\n",
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,52,54,56,61,62,72,100,112) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path,header=10)\n",
      "/Users/pvacca/git/project-google-arxr-analytics/analysis/utils.py:310: DtypeWarning: Columns (13,14,15,16,17,18,19,20,26,28,37,45,48,51,52,54,56,59,61,62,72,112,113) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path,header=10)\n",
      "100%|██████████| 4950/4950 [08:45<00:00,  9.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label distribution for categories amazon is: \n",
      " with singular results\n",
      "llm_label\n",
      "0    0.621141\n",
      "1    0.348199\n",
      "2    0.030660\n",
      "Name: count, dtype: float64\n",
      "The label distribution for categories amazon is: \n",
      " with all results\n",
      "llm_label\n",
      "0.0    0.616724\n",
      "1.0    0.355295\n",
      "2.0    0.027981\n",
      "Name: count, dtype: float64\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: '../data/predictions/categories'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m querys \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategories\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(tags))]\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query,tag \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(querys,tags):\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mmake_preds_categories\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[26], line 64\u001b[0m, in \u001b[0;36mmake_preds_categories\u001b[0;34m(query, tag)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(all_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllm_label\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(all_results))\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m# Save data\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m \u001b[43mall_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/predictions/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mquery\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mtag\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrecords\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mComplete\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/git/project-google-arxr-analytics/.venv/lib/python3.9/site-packages/pandas/util/_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    332\u001b[0m     )\n\u001b[0;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/project-google-arxr-analytics/.venv/lib/python3.9/site-packages/pandas/core/generic.py:2702\u001b[0m, in \u001b[0;36mNDFrame.to_json\u001b[0;34m(self, path_or_buf, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options, mode)\u001b[0m\n\u001b[1;32m   2699\u001b[0m config\u001b[38;5;241m.\u001b[39mis_nonnegative_int(indent)\n\u001b[1;32m   2700\u001b[0m indent \u001b[38;5;241m=\u001b[39m indent \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 2702\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_json\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2703\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2704\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2705\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdouble_precision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdouble_precision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_ascii\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefault_handler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2712\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2717\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/project-google-arxr-analytics/.venv/lib/python3.9/site-packages/pandas/io/json/_json.py:217\u001b[0m, in \u001b[0;36mto_json\u001b[0;34m(path_or_buf, obj, orient, date_format, double_precision, force_ascii, date_unit, default_handler, lines, compression, index, indent, storage_options, mode)\u001b[0m\n\u001b[1;32m    213\u001b[0m     s \u001b[38;5;241m=\u001b[39m convert_to_line_delimits(s)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m path_or_buf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    220\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle\u001b[38;5;241m.\u001b[39mwrite(s)\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/git/project-google-arxr-analytics/.venv/lib/python3.9/site-packages/pandas/io/common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[0;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[1;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[0;32m~/git/project-google-arxr-analytics/.venv/lib/python3.9/site-packages/pandas/io/common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[0;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: Cannot save file into a non-existent directory: '../data/predictions/categories'"
     ]
    }
   ],
   "source": [
    "tags = ['amazon','apple','google','meta','microsoft']\n",
    "querys = ['categories' for i in range(len(tags))]\n",
    "\n",
    "for query,tag in zip(querys,tags):\n",
    "    make_preds_categories(query,tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94372824",
   "metadata": {},
   "source": [
    "# Load in final preds data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89789e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "headsets_predictions = glob.glob('../data/predictions/headsets/*')\n",
    "data = []\n",
    "for path in headsets_predictions:\n",
    "    df = pd.read_json(path,orient='records',lines=True)\n",
    "    data.append(df)\n",
    "all_headsets_preds = pd.concat(data).reset_index(drop=True)\n",
    "all_headsets_preds['query'] = 'headsets'\n",
    "all_headsets_preds.to_json('../data/predictions/final_preds/headsets.json',orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c33e84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_predictions = glob.glob('../data/predictions/categories/*')\n",
    "data = []\n",
    "for path in categories_predictions:\n",
    "    df = pd.read_json(path,orient='records',lines=True)\n",
    "    data.append(df)\n",
    "all_cat_preds = pd.concat(data).reset_index(drop=True)\n",
    "all_cat_preds['query'] = 'categories'\n",
    "all_cat_preds.to_json('../data/predictions/final_preds/categories.json',orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a24306c",
   "metadata": {},
   "source": [
    "# Combine ALL predictions into one single dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9b80163",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = glob.glob('../data/predictions/final_preds/*')\n",
    "data = []\n",
    "for path in all_predictions:\n",
    "    df = pd.read_json(path,orient='records',lines=True)\n",
    "    data.append(df)\n",
    "all_preds = pd.concat(data).reset_index(drop=True)\n",
    "all_preds.to_json('../data/predictions/final_preds/all_preds.json',orient='records',lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
