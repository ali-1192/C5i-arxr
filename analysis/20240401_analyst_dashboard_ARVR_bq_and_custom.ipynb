{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a538a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os \n",
    "import json\n",
    "from google.cloud import bigquery\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"credentials_gpe-analytics.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee00889d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2024-01-01'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44cc5825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants \n",
    "gcs_folder = 'project-google-arxr-analytics-20240401'\n",
    "gcs_bucket = 'mm-gpe-data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c8c373",
   "metadata": {},
   "source": [
    "# What\n",
    "\n",
    "\n",
    "\n",
    "1. New twitter/news/insta needs combined with previous table \n",
    "CREATE new_updated_table\n",
    "SELECT * FROM current_table\n",
    "JOIN new_table \n",
    "WHERE current_table.updated_source=Reddit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f36c207",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexingError",
     "evalue": "Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m new_preds \u001b[38;5;241m=\u001b[39m all_preds\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39mall_preds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPage Type\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna()]\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# Remove all Reddit values \u001b[39;00m\n\u001b[1;32m      3\u001b[0m old_preds \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/predictions/final_preds/old_preds.json\u001b[39m\u001b[38;5;124m'\u001b[39m,orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m,lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m old_preds \u001b[38;5;241m=\u001b[39m \u001b[43mold_preds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mall_preds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPage Type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m final_preds \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([new_preds,old_preds])\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_eval_env/lib/python3.10/site-packages/pandas/core/indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1100\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   1102\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[0;32m-> 1103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_eval_env/lib/python3.10/site-packages/pandas/core/indexing.py:1325\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1323\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_slice_axis(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[0;32m-> 1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getbool_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;66;03m# an iterable multi-selection\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(labels, MultiIndex)):\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_eval_env/lib/python3.10/site-packages/pandas/core/indexing.py:1121\u001b[0m, in \u001b[0;36m_LocationIndexer._getbool_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getbool_axis\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, axis: AxisInt):\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# caller is responsible for ensuring non-None axis\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis)\n\u001b[0;32m-> 1121\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_bool_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1122\u001b[0m     inds \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_take_with_is_copy(inds, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/anaconda3/envs/llm_eval_env/lib/python3.10/site-packages/pandas/core/indexing.py:2506\u001b[0m, in \u001b[0;36mcheck_bool_indexer\u001b[0;34m(index, key)\u001b[0m\n\u001b[1;32m   2504\u001b[0m indexer \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_indexer_for(index)\n\u001b[1;32m   2505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01min\u001b[39;00m indexer:\n\u001b[0;32m-> 2506\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\n\u001b[1;32m   2507\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnalignable boolean Series provided as \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2508\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexer (index of the boolean Series and of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2509\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe indexed object do not match).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2510\u001b[0m     )\n\u001b[1;32m   2512\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   2514\u001b[0m \u001b[38;5;66;03m# fall through for boolean\u001b[39;00m\n",
      "\u001b[0;31mIndexingError\u001b[0m: Unalignable boolean Series provided as indexer (index of the boolean Series and of the indexed object do not match)."
     ]
    }
   ],
   "source": [
    "new_preds = pd.read_json('../data/predictions/final_preds/all_preds.json',orient='records',lines=True)\n",
    "new_preds = all_preds.loc[~all_preds['Page Type'].isna()].reset_index(drop=True) # Remove all Reddit values \n",
    "old_preds = pd.read_json('../data/predictions/final_preds/old_preds.json',orient='records',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dabb841",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_preds = old_preds.loc[old_preds['Page Type'].isna()].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a0043d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = pd.concat([new_preds,old_preds]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ddaa9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds.to_json(\"../data/predictions/final_preds/04012024_final_preds.json\",orient=\"records\",lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96d17ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_preds_configuration(df):\n",
    "    \n",
    "    # Change date column to timestamp\n",
    "    df['date'] = df['date'].combine_first(df['Date'])\n",
    "    df['author'] = df['author'].combine_first(df['Author'])\n",
    "    \n",
    "    #Combine author for the news \n",
    "    df['author'] = df['author'].combine_first(df['Domain'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Now convert timestamp to string '2022-12-12'\n",
    "    df['date'] = df['date'].dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Add engagements for twitter and reddit \n",
    "    \n",
    "    # Twitter\n",
    "    df['Engagements'] = df.apply(lambda x: x['Twitter Likes'] + x['Twitter Retweets'],axis=1)\n",
    "    # Reddit\n",
    "    df['engagements'] = df['redditScore'].combine_first(df['Engagements'])\n",
    "    \n",
    "    # Create updated source column\n",
    "    df['updated_source'] = df.apply(lambda x: x['Page Type'] if x['Page Type'] else 'reddit',axis=1)\n",
    "    \n",
    "    df['link_url'] = df.apply(lambda x: x.uid if x.updated_source!='reddit' else x.url,axis=1)\n",
    "    \n",
    "    \n",
    "    return df \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19e0ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds = all_preds_configuration(final_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec22257f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Table \n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0c59944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christiannaclark/anaconda3/envs/llm_eval_env/lib/python3.10/site-packages/google/cloud/bigquery/_pandas_helpers.py:603: UserWarning: Pyarrow could not determine the type of columns: categoryDetails, displayUrls, expandedUrls, insightsHashtag, insightsMentioned, interest, matchPositions, professions, shortUrls, subscriptions, copyright, classifications, entityInfo, imageInfo, logoImages.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Create Table \n",
    "client = bigquery.Client()\n",
    "# Define table name, in format dataset.table_name\n",
    "table = f'gpe-analytics.{gcs_folder.replace(\"-\",\"_\")}.ar_xr_predictions_updated'\n",
    "\n",
    "# Load data to BQ\n",
    "job = client.load_table_from_dataframe(final_preds, table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ac8227",
   "metadata": {},
   "source": [
    "# Do Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4c9d0325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'uid', 'source', 'date'])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing keys \n",
    "{\"text\":\"Would you prefer for Apple to adapt to the industry standard of RCS? #fyp #android #apple #iphone #samsung #google #ipager #phone #greenbubble #bluebubble #rcs #androidvsiphone #getthemessage\",\"uid\":\"https:\\/\\/www.tiktok.com\\/@redirect-to\\/video\\/7287566836936346912\",\"source\":\"tiktok\",\"date\":\"2024-01-04\"}.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "22a83cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['source', 'author', 'engagements', 'link', 'uid', 'date', 'queryName', 'query_title', 'subreddit', 'sentiment'])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label map keys \n",
    "{\"source\": \"Platform\", \"author\": \"NULL\", \"engagements\": \"NULL\", \"link\": \"Video_URL\", \"uid\": \"Video_URL\", \"date\": \"date\", \"queryName\": \"NULL\", \"query_title\": \"Video_Title\", \"subreddit\": \"NULL\", \"sentiment\": \"NULL\"}.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "66d17fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data = final_preds[['date','text','uid','source']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "036abfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_data.to_json('preprocessed_data.json',orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7fd44293",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://preprocessed_data.json [Content-Type=application/json]...\n",
      "\\ [1 files][ 44.9 MiB/ 44.9 MiB]                                                \n",
      "Operation completed over 1 objects/44.9 MiB.                                     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(f'gsutil cp preprocessed_data.json gs://{gcs_bucket}/{gcs_folder}/preprocessed/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "41ebdd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://data_label_map.json [Content-Type=application/json]...\n",
      "/ [0 files][    0.0 B/  195.0 B]                                                \r",
      "/ [1 files][  195.0 B/  195.0 B]                                                \r\n",
      "Operation completed over 1 objects/195.0 B.                                      \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {'source':'source',\n",
    "            'author':'author',\n",
    "            'engagements':'NULL',\n",
    "            'link':'NULL',\n",
    "            'uid':'uid',\n",
    "            'date':'date',\n",
    "            'queryName':'NULL',\n",
    "            'query_title':'NULL',\n",
    "            'subreddit':'NULL',\n",
    "            'sentiment':'NULL'}\n",
    "\n",
    "\n",
    "with open('data_label_map.json','w') as f:\n",
    "    json.dump(label_map,f)\n",
    "    \n",
    "os.system(f'gsutil cp data_label_map.json gs://{gcs_bucket}/{gcs_folder}/label_maps/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "efca5257",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying file://raw_data.json [Content-Type=application/json]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "/ [1 files][ 1006 MiB/ 1006 MiB]   47.6 MiB/s                                   \n",
      "Operation completed over 1 objects/1006.7 MiB.                                   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final_preds.to_json('raw_data.json',orient='records',lines=True)\n",
    "os.system(f'gsutil cp raw_data.json gs://{gcs_bucket}/{gcs_folder}/raw/')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a73e302",
   "metadata": {},
   "source": [
    "# Kick off new pipeline to obtain predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6724b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SELECT \n",
    "    * \n",
    "    FROM \n",
    "    (\n",
    "        SELECT \n",
    "        DISTINCT LEFT(text, 300) AS text, \n",
    "        uid, \n",
    "        category_1, \n",
    "        probability_1, \n",
    "        category_2, \n",
    "        probability_2, \n",
    "        subreddit_category_1,\n",
    "        subreddit_probability_1\n",
    "        FROM \n",
    "        `gpe-analytics.project_google_arxr_analytics_20240109.redditnlp_output`\n",
    "    )  \n",
    "    LEFT JOIN (SELECT source ,uid,date engagements as NULL from gpe-analytics.project_google_arxr_analytics_20240109.raw_data) USING (uid)\n",
    "    LEFT JOIN (\n",
    "        SELECT \n",
    "        * \n",
    "        FROM \n",
    "        `gpe-analytics.project_google_arxr_analytics_20240109.clusters`\n",
    "    ) USING (uid) \n",
    "    LEFT JOIN (SELECT * FROM `gpe-analytics.project_google_arxr_analytics_20240109.custom_nlp_tags`) USING (uid) LEFT JOIN (SELECT text as raw_text, uid,  FROM `gpe-analytics.project_google_arxr_analytics_20240109.raw_data`) USING (uid)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0eb49d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'project_google_arxr_analytics_20240401'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"project-google-arxr-analytics-20240401\".replace(\"-\",\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555320dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE TABLE `gpe-analytics.project_google_arxr_analytics_20240401.view_dashboard_final_update` as SELECT \n",
    "    * \n",
    "    FROM \n",
    "    (\n",
    "        SELECT \n",
    "        DISTINCT LEFT(text, 300) AS text, \n",
    "        uid, \n",
    "        category_1, \n",
    "        probability_1, \n",
    "        category_2, \n",
    "        probability_2, \n",
    "        subreddit_category_1,\n",
    "        subreddit_probability_1\n",
    "        FROM \n",
    "        `gpe-analytics.project_google_arxr_analytics_20240401.redditnlp_output`\n",
    "    )  \n",
    "    LEFT JOIN (SELECT updated_source ,link_url,uid,date_,query, tag, llm_label, engagements_ from `gpe-analytics.project_google_arxr_analytics_20240401.ar_xr_predictions_table_update`) USING (uid)\n",
    "    LEFT JOIN (\n",
    "        SELECT \n",
    "        * \n",
    "        FROM \n",
    "        `gpe-analytics.project_google_arxr_analytics_20240401.clusters`\n",
    "    ) USING (uid) \n",
    "    LEFT JOIN (SELECT * FROM `gpe-analytics.project_google_arxr_analytics_20240401.custom_nlp_tags`) USING (uid) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df5308a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d006fdb5",
   "metadata": {},
   "source": [
    "# 2024/01/16 Create Clustering Dashboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "208e99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = pd.read_json('../data/predictions/final_preds/all_preds.json',orient='records',lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ad146542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "Query Id\n",
      "Query Name\n",
      "Date\n",
      "Title\n",
      "text\n",
      "uid\n",
      "Domain\n",
      "Sentiment\n",
      "Emotion\n",
      "Page Type\n",
      "Language\n",
      "Country Code\n",
      "Continent Code\n",
      "Continent\n",
      "Country\n",
      "Region Code\n",
      "Region\n",
      "City Code\n",
      "Account Type\n",
      "Assignment\n",
      "Author\n",
      "Avatar\n",
      "Category Details\n",
      "Checked\n",
      "City\n",
      "Display URLs\n",
      "Expanded URLs\n",
      "Facebook Author ID\n",
      "Facebook Comments\n",
      "Facebook Likes\n",
      "Facebook Role\n",
      "Facebook Shares\n",
      "Facebook Subtype\n",
      "Full Name\n",
      "Gender\n",
      "Hashtags\n",
      "Impact\n",
      "Impressions\n",
      "Instagram Comments\n",
      "Instagram Followers\n",
      "Instagram Following\n",
      "Instagram Likes\n",
      "Instagram Posts\n",
      "Interest\n",
      "Last Assignment Date\n",
      "Latitude\n",
      "Location Name\n",
      "Longitude\n",
      "Media Filter\n",
      "Media URLs\n",
      "Mentioned Authors\n",
      "Priority\n",
      "Professions\n",
      "Resource Id\n",
      "Short URLs\n",
      "Starred\n",
      "Status\n",
      "Subtype\n",
      "Tags\n",
      "Thread Author\n",
      "Thread Created Date\n",
      "Thread Entry Type\n",
      "Thread Id\n",
      "Thread URL\n",
      "Total Monthly Visitors\n",
      "Twitter Author ID\n",
      "Twitter Channel Role\n",
      "Twitter Followers\n",
      "Twitter Following\n",
      "Twitter Reply Count\n",
      "Twitter Reply to\n",
      "Twitter Retweet of\n",
      "Twitter Retweets\n",
      "Twitter Likes\n",
      "Twitter Tweets\n",
      "Twitter Verified\n",
      "Reach (new)\n",
      "Reddit Score\n",
      "Reddit Score Upvote Ratio\n",
      "Reddit Author Karma\n",
      "Reddit Author Awardee Karma\n",
      "Reddit Author Awarder Karma\n",
      "Reddit Comments\n",
      "Subreddit\n",
      "Subreddit Subscribers\n",
      "Sina Weibo Post Count\n",
      "Sina Weibo Favourites Count\n",
      "Sina Weibo Followers\n",
      "Sina Weibo Following\n",
      "Sina Weibo Bi Followers\n",
      "Sina Weibo Raw Location\n",
      "AI Image Generation\n",
      "Android Scorecard Trending Topics\n",
      "App store Robinhood Filter\n",
      "Chrome EOY Review | Competitors\n",
      "Chrome: Promote Key Topics\n",
      "Google AR/VR: Categories\n",
      "Google AR/VR: Companies\n",
      "Google AR/VR: Glasses\n",
      "Google AR/VR: Headsets\n",
      "Google P&E X-Brand Brand Pulse Categories\n",
      "K-pop Exclusion\n",
      "P&E Verticals 2020\n",
      "Switching Snapshot: Competitors\n",
      "Switching Snapshot: Platforms\n",
      "Switching Snapshot: SPICES filters\n",
      "[Chrome AI Snap] Browsers\n",
      "[Chrome AI Snap] ChatGPT vs Bard\n",
      "[Chrome AI Snap] Search Engines\n",
      "tag\n",
      "IRGC\n",
      "source\n",
      "accountType\n",
      "added\n",
      "assignment\n",
      "author\n",
      "authorVerifiedType\n",
      "avatarUrl\n",
      "blogName\n",
      "broadcastMediaUrl\n",
      "isSyndicated\n",
      "airType\n",
      "broadcastType\n",
      "mediaType\n",
      "categories\n",
      "categoryDetails\n",
      "checked\n",
      "city\n",
      "cityCode\n",
      "continent\n",
      "continentCode\n",
      "country\n",
      "countryCode\n",
      "region\n",
      "regionCode\n",
      "date\n",
      "displayUrls\n",
      "domain\n",
      "engagementType\n",
      "expandedUrls\n",
      "facebookAuthorId\n",
      "facebookComments\n",
      "facebookLikes\n",
      "facebookRole\n",
      "facebookShares\n",
      "facebookSubtype\n",
      "fullname\n",
      "gender\n",
      "impressions\n",
      "insightsHashtag\n",
      "insightsMentioned\n",
      "instagramCommentCount\n",
      "instagramFollowerCount\n",
      "instagramFollowingCount\n",
      "instagramInteractionsCount\n",
      "instagramLikeCount\n",
      "instagramPostCount\n",
      "interest\n",
      "itemReview\n",
      "language\n",
      "lastAssignmentDate\n",
      "latitude\n",
      "linkedinComments\n",
      "linkedinEngagement\n",
      "linkedinImpressions\n",
      "linkedinLikes\n",
      "linkedinShares\n",
      "linkedinSponsored\n",
      "linkedinVideoViews\n",
      "locationName\n",
      "longitude\n",
      "matchPositions\n",
      "mediaFilter\n",
      "mediaUrls\n",
      "monthlyVisitors\n",
      "originalUrl\n",
      "pageType\n",
      "parentPostId\n",
      "parentBlogName\n",
      "priority\n",
      "professions\n",
      "pubType\n",
      "publisherSubType\n",
      "queryId\n",
      "queryName\n",
      "rating\n",
      "reachEstimate\n",
      "redditScore\n",
      "redditScoreUpvoteRatio\n",
      "redditComments\n",
      "redditAuthorKarma\n",
      "redditAuthorAwardeeKarma\n",
      "redditAuthorAwarderKarma\n",
      "replyTo\n",
      "resourceType\n",
      "retweetOf\n",
      "rootPostId\n",
      "rootBlogName\n",
      "sentiment\n",
      "sinaWeiboAuthorId\n",
      "sinaWeiboFollowers\n",
      "sinaWeiboFollowing\n",
      "sinaWeiboBiFollowers\n",
      "sinaWeiboPostCount\n",
      "sinaWeiboFavouritesCount\n",
      "sinaWeiboRawLocation\n",
      "shortUrls\n",
      "snippet\n",
      "starred\n",
      "status\n",
      "subreddit\n",
      "subredditSubscribers\n",
      "subscriptions\n",
      "subtype\n",
      "tags\n",
      "threadAuthor\n",
      "threadCreated\n",
      "threadEntryType\n",
      "threadId\n",
      "threadURL\n",
      "title\n",
      "twitterAuthorId\n",
      "twitterFollowers\n",
      "twitterFollowing\n",
      "twitterPostCount\n",
      "twitterReplyCount\n",
      "twitterRetweets\n",
      "twitterLikeCount\n",
      "twitterRole\n",
      "twitterVerified\n",
      "updated\n",
      "url\n",
      "copyright\n",
      "weblogTitle\n",
      "classifications\n",
      "pageTypeName\n",
      "contentSource\n",
      "contentSourceName\n",
      "impact\n",
      "resourceId\n",
      "entityInfo\n",
      "imageMd5s\n",
      "imageInfo\n",
      "logoImages\n",
      "llm_label\n",
      "query\n"
     ]
    }
   ],
   "source": [
    "for x in all_preds.columns:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1d85d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds['twitter_engagements']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_eval_env",
   "language": "python",
   "name": "llm_eval_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
